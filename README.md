# ISACT2024

Giulia D'Angelo, giulia.dangelo@fel.cvut.cz

LinkedIn: [Giulia D'Angelo](https://www.linkedin.com/in/giuliadangelo/)

# Introduction to Event-Based Cameras & Neuromorphic Vision 

## What are Event-Based Cameras? 📸
Unlike traditional cameras that capture full images at fixed intervals (e.g., 30 or 60 times per second), **event-based cameras** work differently. These cameras are designed to capture **changes** in the scene — pixel by pixel! Instead of taking pictures of the entire scene at once, they only capture what *moves* or *changes* in brightness. 📍✨

![events](Images/example.gif)

Copyrigths for the GIF, Arren Glover, Italian Institute of Technology


**Do you want to know more?** Look at my [CTUTalk](Images/CTUtalk.pdf)


### How They Work 
- Each pixel in an event-based camera works **independently** and detects changes in brightness 🎥.
- When a pixel detects a change, it sends out an **event** 🚀 (instead of a frame). This means less data is collected for static areas, saving **memory** and **energy** 🔋.

## Why is it so Cool? 
- **Ultra-fast**: They capture events as they happen, with no delay!
- **Efficient**: Only relevant information is collected, making them great for devices with limited resources.
- **Motion detection**: They excel at capturing fast movements like sports, drones in flight, or self-driving cars 🏎️.

## Neuromorphic Vision: What’s That? 
Neuromorphic vision systems mimic the way our **brain** and **eyes** work! 👁️🧠 The idea is to create cameras and chips that process visual information more like human vision, reacting to changes in the environment in **real-time**. 

These systems use **event-based cameras** to collect data and neuromorphic processors to make decisions, just like how our brain reacts to what we see in milliseconds. 🤯

### Benefits of Neuromorphic Vision Systems 
- **Real-time processing**: Instant reactions without waiting for a full image.
- **Power efficiency**: By focusing only on changes, these systems save energy and reduce data overload.
- **Biologically inspired**: They simulate how **our neurons** work, making them more adaptive and responsive.

## Cool Applications 🛠️
- **Robotics** : Robots equipped with event-based cameras can navigate dynamic environments more smoothly!
- **Self-driving cars** : They use these cameras to react instantly to objects on the road.
- **Sports** : Capture high-speed sports actions and improve player performance analysis.
- **Healthcare** : Monitoring eye movements for diagnosing medical conditions.

## Want to Learn More? 📚
If you're curious about how the brain 🧠 can inspire technology, **neuromorphic vision** is the perfect place to start! With these futuristic tools, we can create smarter, faster, and more efficient systems. 🌍✨

Check out the for a hands-on introduction!

Do you want to see what events look like? Here you have a tutorial for you: 
- [Real Data](https://github.com/GiuliaDAngelo/EDtutorial/blob/main/realdata.py)

Do you want to create a neuron and see its behaviour?
- [Neuron tutorial](https://github.com/GiuliaDAngelo/EDtutorial/blob/main/neuron.py)

## References 📚
Here are some valuable resources to learn more about event-based cameras and neuromorphic vision:

   - [Event-Based Vision: A Survey](https://ieeexplore.ieee.org/abstract/document/9138762) by Gallego et al. – A comprehensive survey of event-based vision systems.
   - [Neuromorphic Engineering](https://link.springer.com/chapter/10.1007/978-3-662-43505-2_38) by Giacomo Indiveri – An overview of neuromorphic engineering principles and applications.


